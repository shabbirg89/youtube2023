{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "# !pip install langchain\n",
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import openai\n",
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "load_dotenv()\n",
    "# API configuration\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shabbirgovernor/Library/Python/3.9/lib/python/site-packages/langchain/llms/openai.py:173: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/Users/shabbirgovernor/Library/Python/3.9/lib/python/site-packages/langchain/llms/openai.py:753: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'As of 2020, the per capita income in India is estimated to be around $2,104.'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo\",temperature=0.9)\n",
    "\n",
    "# The LLM takes a prompt as an input and outputs a completion\n",
    "prompt = \"What is the per capita income of a indiviual in India\"\n",
    "completion = llm(prompt)\n",
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Pizzas can be enjoyed in moderation as part of a balanced diet. Opt for whole wheat crust, lean protein toppings, and plenty of vegetables to make it healthier. However, it's important to consider portion sizes and limit consumption of high-fat and processed toppings.\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set System behaviour for Chat\n",
    "chat = ChatOpenAI(temperature=0)\n",
    "\n",
    "chat([SystemMessage(content=\"You are a AI bot which replys user what to eat in three short sentence\"),\n",
    "        HumanMessage(content=\"Are pizzas healthy, Should I eat them?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04051665  0.01633171 -0.00271362 ...  0.00470819  0.00965397\n",
      " -0.0272362 ]\n",
      "[-0.00831975 -0.015002   -0.01128614 ... -0.00722388 -0.03559668\n",
      " -0.0221566 ]\n"
     ]
    }
   ],
   "source": [
    "# Embedding text with Langchain \n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "text = \"I dont like studying. Dont make me study\"\n",
    "text1 = \"Maria has a parrot. Where do parrots live?\"\n",
    "text_embedding = np.array(embeddings.embed_query(text))\n",
    "text_embedding1 = np.array(embeddings.embed_query(text1))\n",
    "print(text_embedding)\n",
    "print(text_embedding1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.70411446]]\n"
     ]
    }
   ],
   "source": [
    "list1 = text_embedding.reshape(1, -1)\n",
    "list2 = text_embedding1.reshape(1, -1)\n",
    "\n",
    "similarity = cosine_similarity(list1, list2)\n",
    "\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Technically, Narendra Modi, being the current Prime Minister of India, cannot have a physical conversation with Mahatma Gandhi, as Gandhi passed away in 1948. However, if we are considering a hypothetical scenario in which time travel or some form of communication beyond physical existence is possible, then it would be conceivable for Narendra Modi to have a conversation with Mahatma Gandhi.'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt templates in Langchain\n",
    "llm(\"Can Narendra Modi have a conversation with Mahatma Gandhi?\")\n",
    "prompt = \"\"\"Question: Can Narendra Modi have a conversation with Mahatma Gandhi?\n",
    "\n",
    "Let's think step by step.\n",
    "\n",
    "Answer: \"\"\"\n",
    "llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'product': 'colorful socks', 'text': '\\n\\nSocktastic!'}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chaining \n",
    "from langchain import PromptTemplate, OpenAI, LLMChain\n",
    "\n",
    "prompt_template = \"What is a good name for a company that makes {product}?\"\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=PromptTemplate.from_template(prompt_template)\n",
    ")\n",
    "llm_chain(\"colorful socks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '\\n\\nCozy Toes Socks.'},\n",
       " {'text': '\\n\\nTechCore Solutions.'},\n",
       " {'text': '\\n\\nFootwear Factory.'}]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_list = [\n",
    "    {\"product\": \"socks\"},\n",
    "    {\"product\": \"computer\"},\n",
    "    {\"product\": \"shoes\"}\n",
    "]\n",
    "\n",
    "llm_chain.apply(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[Generation(text='\\n\\nCozy Toes Socks.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nTechCore Solutions.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nFootwear Factory.', generation_info={'finish_reason': 'stop', 'logprobs': None})]], llm_output={'token_usage': {'total_tokens': 57, 'prompt_tokens': 36, 'completion_tokens': 21}, 'model_name': 'text-davinci-003'}, run=[RunInfo(run_id=UUID('8534a09c-e08c-4fcb-8575-3dab8f828837')), RunInfo(run_id=UUID('80f8fb9a-8296-4be6-81ad-23dde5d35e0f')), RunInfo(run_id=UUID('e7c1e9d5-120a-4f32-9cd1-5691b45e13b3'))])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.generate(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nSocktastic!'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single input example\n",
    "llm_chain.predict(product=\"colorful socks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nQ: What did the politician say when he was offered a free trip to the moon?\\nA: \"That\\'s one small step for me, one giant leap for mankind!\"'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiple inputs example\n",
    "\n",
    "template = \"\"\"Tell me a {adjective} joke about {subject}.\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"adjective\", \"subject\"])\n",
    "llm_chain = LLMChain(prompt=prompt, llm=OpenAI(temperature=0))\n",
    "\n",
    "llm_chain.predict(adjective=\"happy\", subject=\"politics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n* When employed effectively, agents can yield significant power by utilizing an LLM to make decisions, execute actions, \\nobserve outcomes, and repeat this process until the desired objective is achieved.\\n\\nTo successfully deploy agents, it is essential to comprehend the following concepts:\\n\\nTool: A specialized function that carries out a specific task. Examples include Google Search, database lookup, Python REPL, and other tool chains.\\n\\nLLM: The language model that empowers the agent and provides it with the ability to understand and generate human-like text.\\n\\nAgent: The designated agent to be utilized for the task at hand.\\n\\n'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agents and Tools\n",
    "\"\"\"\n",
    "* When employed effectively, agents can yield significant power by utilizing an LLM to make decisions, execute actions, \n",
    "observe outcomes, and repeat this process until the desired objective is achieved.\n",
    "\n",
    "To successfully deploy agents, it is essential to comprehend the following concepts:\n",
    "\n",
    "Tool: A specialized function that carries out a specific task. Examples include Google Search, database lookup, Python REPL, and other tool chains.\n",
    "\n",
    "LLM: The language model that empowers the agent and provides it with the ability to understand and generate human-like text.\n",
    "\n",
    "Agent: The designated agent to be utilized for the task at hand.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature=0)\n",
    "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out the year India achieved independence and then use a calculator to calculate the power.\n",
      "Action: Wikipedia\n",
      "Action Input: India Independence\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Indian independence movement\n",
      "Summary: The Indian independence movement was a series of historic events with the ultimate aim of ending British rule in India also known as British Raj. It lasted from 1857 to 1947.\n",
      "The first nationalistic revolutionary movement for Indian independence emerged from Bengal. It later took root in the newly formed Indian National Congress with prominent moderate leaders seeking the right to appear for Indian Civil Service examinations in British India, as well as more economic rights for natives. The first half of the 20th century saw a more radical approach towards self-rule by the Lal Bal Pal triumvirate, Aurobindo Ghosh and V. O. Chidambaram Pillai.\n",
      "The stages independence struggle in the 1920s were characterized by the leadership of Mahatma Gandhi and Congress' adoption of Gandhi's policy of non-violence and civil disobedience. Some of the leading followers of Gandhi's ideology were Jawaharlal Nehru, Vallabhbhai Patel, Abdul Ghaffar Khan, Maulana Azad, and others. Intellectuals such as Rabindranath Tagore, Subramania Bharati, and Bankim Chandra Chattopadhyay spread patriotic awareness. Female leaders like Sarojini Naidu, Vijaya Lakshmi Pandit, Pritilata Waddedar, and Kasturba Gandhi promoted the emancipation of Indian women and their participation in the freedom struggle.\n",
      "Few leaders followed a more violent approach. This became especially popular after the Rowlatt Act, which permitted indefinite detention. The Act sparked protests across India, especially in the Punjab province, where they were violently suppressed in the Jallianwala Bagh massacre.\n",
      "The Indian independence movement was in constant ideological evolution. Essentially anti-colonial, it was supplemented by visions of independent, economic development with a secular, democratic, republican, and civil-libertarian political structure. After the 1930s, the movement took on a strong socialist orientation. It culminated in the Indian Independence Act 1947, which ended Crown suzerainty and partitioned British Raj into Dominion of India and Dominion of Pakistan.\n",
      "India remained a Crown Dominion until 26 January 1950, when the Constitution of India established the Republic of India. Pakistan remained a dominion until 1956 when it adopted its first constitution. In 1971, East Pakistan declared its own independence as Bangladesh.\n",
      "\n",
      "Page: Independence Day (India)\n",
      "Summary: Independence Day is celebrated annually on 15 August as a public holiday in India commemorating the nation's independence from the United Kingdom on 15 August 1947, the day when the provisions of the Indian Independence Act, which transferred legislative sovereignty to the Indian Constituent Assembly, came into effect. India retained King George VI as head of state until its transition to a republic, when the Constitution of India came into effect on 26 January 1950 (celebrated as Indian Republic Day) and replaced the dominion prefix, Dominion of India, with the enactment of the sovereign law Constitution of India. India attained independence following the independence movement noted for largely non-violent resistance and civil disobedience.\n",
      "Independence coincided with the partition of India, in which British India was divided along religious lines into the Dominions of India and Pakistan; the partition was accompanied by violent riots and mass casualties, and the displacement of nearly 15 million people due to religious violence. On 15 August 1947, the first Prime Minister of India, Jawaharlal Nehru raised the Indian national flag above the Lahori Gate of the Red Fort in Delhi. On each subsequent Independence Day, the incumbent Prime Minister customarily raises the flag and gives an address to the nation. The entire event is broadcast by Doordarshan, India's national broadcaster, and usually begins with the shehnai music of Ustad Bismillah Khan. Independence Day is observed throughout India with flag-hoisting ceremonies, parades and cultural events. It is a national holid\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the year India achieved independence\n",
      "Action: Calculator\n",
      "Action Input: 1947^3\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 7380705123\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: India achieved independence in 1947 and this year raised to the power 3 is 7380705123.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'India achieved independence in 1947 and this year raised to the power 3 is 7380705123.'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"In what year India achieved Indepence? What is this year raised to the power 3?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory\n",
    "\"\"\"\n",
    "State refers to the concept of retaining information between successive calls of a chain or agent. \n",
    "In LangChain, a standardized interface for managing state, known as memory, is provided. This memory functionality encompasses\n",
    " various implementations and includes examples of chains and agents that leverage this feature effectively.\n",
    "\n",
    "By employing memory, chains and agents can store and access relevant information throughout their execution, \n",
    "enabling them to maintain context and make informed decisions based on past observations or actions.\n",
    "\n",
    "The term \"memory\" in this context denotes the ability of the system to retain and recall data as needed, \n",
    "facilitating continuity and coherence in the chain or agent's behavior.\n",
    "\n",
    "LangChain offers a range of memory implementations, allowing developers to choose the most suitable option for their specific \n",
    "use case. This flexibility empowers chains and agents to effectively utilize and manage state information, \n",
    "enhancing their overall performance and adaptability.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hi there! It's nice to meet you. How can I help you today?\""
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import OpenAI, ConversationChain\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "conversation = ConversationChain(llm=llm, verbose=True)\n",
    "\n",
    "conversation.predict(input=\"Hi there!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: Can we talk about climate?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Sure! What would you like to know about climate?'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Can we talk about climate?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: Can we talk about climate?\n",
      "AI:  Sure! What would you like to know about climate?\n",
      "Human: Is the current world climate good?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" That's a difficult question to answer. The current climate is changing rapidly, and it's hard to say whether it's good or bad. However, it's clear that the climate is changing in ways that are having a negative impact on the environment and human life.\""
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Is the current world climate good?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: Can we talk about climate?\n",
      "AI:  Sure! What would you like to know about climate?\n",
      "Human: Is the current world climate good?\n",
      "AI:  That's a difficult question to answer. The current climate is changing rapidly, and it's hard to say whether it's good or bad. However, it's clear that the climate is changing in ways that are having a negative impact on the environment and human life.\n",
      "Human: Thats very sad to here\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Yes, it is. We need to take action to reduce the effects of climate change and protect our planet.'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Thats very sad to here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
